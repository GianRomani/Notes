Created: 2024-03-12 14:07
#quicknote

One of the [[Vulnerabilities in LLM-base applications]].

Overreliance occurs when users blindly trust information generated by LLMs, even when presented with authority. While LLMs can offer creativity and insight, they are also prone to hallucinations and confabulations, producing incorrect, harmful, or misleading content. 
This poses serious risks:
- **Security Breaches:** Erroneous information can lead to security vulnerabilities if trusted without proper oversight.
- **Misinformation:** Spread of false or misleading information can cause confusion and harm.
- **Legal and Reputational Damage:** Acting on inaccurate LLM outputs can lead to legal issues and undermine an organization's reputation.
- **Vulnerable Code:** LLM-generated source code may contain hidden security flaws, putting systems at risk.

**Mitigation Strategies**
- **Rigorous Review:** Implement thorough review processes for LLM outputs.
- **Human Oversight:** Maintain human-in-the-loop oversight for critical decisions.
- **Continuous Validation:** Regularly test and validate LLM responses.
- **Clear Disclaimers:** Emphasize the potential for LLM errors and the need for human judgment.
## Resources
1. [OWASP](https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf)

#### Tags
#aisecurity #llm #cybersecurity 