# Sequential RS
Created: 2022-06-14 11:25
#note

Sequential RSs try to understand and model the sequential user behaviors, the interactions between users and items, the evolution of users' preferences and item popularity over time. This means that SRs take the prior sequential interactions as a context to predict which items would be interacted in the near future -> it is easier to diversify the recommendations.
More specifically, given a sequence of user-item interactions $S={i_1,i_2,...,i_{|S|}}$, where each interactions $i_j=<u,a,v>$ is the triple composed by the user *u*, the user's action *a* and the item *v*, the recommedation list is generated by $R=argmax f(S)$. In some cases some meta data can be used, actions of different kinds are considered and context (time, location etc) can vary a lot.
Sub-types of sequential RS are:
- Session-based recommendation -> no long-term user histories are available.
- Session-aware recommendation -> both short-term and long-term user histories are available.

The goal of a SRS's prediction can be:
- **experience-based** -> predict the next behavior type that the user will exert given an item (is he going to like it, buy it or just view it?). [[Multi-task learning]] is a good approach for this type o problems;
- **transaction-based** -> predict the next item the user will interact with (regardless of the type of the interaction). GRU4Rec and similar models, memory models, Hierarchical Periodic Memory Network, ARNN, DREAM, MCPRN, CNNs (NextItNet, HierTCN), Attention based (NARM, SDM, SASRec, [[BERT4Rec]]);
- **interaction-based** -> generalization of the two types listed above, i.e. the RS should be able to understand user preferences in a way that could help us predict both the next item the user will interact with and the way he/she is going to interact with it. RNNs are the most used models -> TA-RLBL.

## Challenges in sequential RSs
We can identify 5 subclasses of challenges.

### Long User-Item Interaction sequences
Higher chance to have more complex and comprehensive dependencies over the multiple interactions inside it. 
Challenges:
- **Learning higher-order sequential dependencies** -> complicated multi-level cascading dependencies across multiple user-item interactions. Two basic approaches that address this challenge are: higher order Markov Chain and RNNs. They both have some limitations though -> RNN's structure is too strict and Markov Chain's oarameters grow exponentially with the order.
- **Learning long-term sequential dependencies** -> dependencies between interactions that are far from each other in a sequence. LSTM and GRU have been applied for this kind of tasks. Some modela wrongly assume that close items are correlated, even when this is not true -> mixture models that combine multiple sub-models with different temporal ranges. This models are still not good enough -> more reasearch is needed ([[Transformer]]?).

### User-Item Interaction sequences with flexible order
In some cases the order of the interactions is not important or an interaction can depend on the union of several past interactions -> we need to capture the collective sequential dependencies. Not much attention was put on this problem, just some models based on CNNs.

### User-Item Interactions sequences with noise
Because of some uncertainties in the behaviours of the users, we could have noisy and irrelevant interactions. Few attempts to solve this problem -> attention models or memory networks.

### User-Item interaction sequences with Heterogeneous Relations
Relation could be of different types and deliver different kinds of information, for example we could have both short-term and long-term sequences. Mixture models are the most used.

### User-Item Interaction sequences with Hierarchical structures
We can consider two kinds of hierarchical structures:
- hierarchical structure between meta data and user-item interactions -> users' demographics can determine the users' preferences in some degree;
- hierarchical structure between sub-sequences and user-item interactions ->one user-item interaction can include mmultiple sub-sequences.

Hirarchical embedding models and hirarchical attention networks ahve been used.




## Categorization of SRS approaches
![[Categorizarion of SRS approaches.png]]

### Traditional Sequence Models
Main approaches:
- **Sequential pattern mining** -> methods that mine frequent patterns on sequence data and then utilize them to guide the subsequent recommendations. Simple and straightforward methods but they generates redundant patterns and generally focus on popular items, losing infrequent patterns;
- **Markov chain models** -> transitions over user-item interactions are modeled in a sequence. Basic MC approaches compute the transition probability based on explicit observations, latent MC embedding approaches embed MC into an Euclidean space and the compute the transition probabilities between interactions based on their Euclidean distance (use [this](https://www.ijcai.org/Proceedings/15/Papers/293.pdf) paper as reference). MC-based RSs can capture only short-term dependencies;
- [[kNN]] -> in item-based KNN, we consider just the last interaction and recommend items that are the most similar to it, in session-based KNN, instead, the entire existing session is compared to all the past sessions (using Jaccard similarity for example)

### Latent representation models
These models first learn a latent representation of each user and item and then predict the subsequent user-item interactions by using such representations. More implicit and complex dependencies are captured. The most representative models for this category are:
- **Factorization machines** ->user-item interactions are factorized into latent factors by [[Matrix factorization]] or tensor factorization. In this case, instead of the ratings (as happens in [[Collaborative filtering]]), the matrix is composed of interactions.
- **Embeddings** -> the latent representation for users and items is learnt by encoding all the user-item interactions in a sequence into a latent space. These latent representations can be directly used to calculate the interaction score or can be fed to networks. This approach seems to be the most promising.

### Reinforcement Learning
Goal: update recommendations according to the interactions between users and the recommender systems, i.e. a positive reward is assigned if the user express his interest on a recommended item. It is generally formulated as a Markov decision process with the goal of maximizing the cumulative rewards in a set of interactions.
Problem: lack of interpretability.
### Deep Neural Network models
The often reach SOTA results but they have also some weaknesses, for example they largely emphasize item representation over user representation and often consider all interactions as they belong to only one type.
The most used approaches are:
- [[RNN]] (and variants) -> naturally made to model sequential dependencies. They have also some shortcomings: they don't consider the assumption of existence of noisy data and, even if they are able to deal with longer sequences, they can not really capture collective dependencies;
- [[CNN]] -> this kind of models puts all the interactions into a matrix and then treats them as an image. They do not have strong order assumption over the interactions in a sequence, they rather learn patterns within areas of the "image", so they cannot effectively capture long-term dependencies. The computing cost for CNNs are smaller than the ones for RNNs;
- [[GNN]] -> each interaction is a node and then a sequence is a path in the graph. Embeddings of users or items are learned on the graph. Great potentioal to provide explainable recommendations;
- [[Neural attention]] models -> they emphasize the interactions that are really relevant;
- **Memory networks** -> by using an external matrix, these models can capture the dependencies between any historical user-item interaction and the next one. This matrix stores and update the historical interactions in a sequence more explicitly and dynamically, i.e. it reduces the interference caused by irrelevant interactions;
- **Mixture models** -> the combine different models;

## Other important aspects

- **Context-aware SRS** -> context couldheavily influence the user's choice;
- **Social-aware SRS** -> others' behaviors or opinions often affect the users' choices;
- **Interactive SRS** -> Multi-time step recommendations, for example in e-commerce RS we should consider users' behaviors as continuous rather than isolated events;
- **Cross-domain SRS** -> there could be sequential dependencies between items from different domains (for example, the purchase of a car insurance after the purcahse of a car).

## Input Module
### Side Information
Side information (images, text description, dwell time etc) can be used to improve the recommendations. Models like [p-RNN](https://dl.acm.org/doi/pdf/10.1145/2959100.2959167?casa_token=OIRhtMXXltMAAAAA:k1sJRHomehw5og8QnbaEK3WxqEqSrzBHlEWWMnaMcCPIr05O3d8DUAqLKwM_8Xr-5BmBtqULYh0) or [CSAN](https://dl.acm.org/doi/pdf/10.1145/3240508.3240609) uses parallel RNNs to process item IDs, images and texts which hidden layers are then concatenated to generate the input.

### Data Processing
There are several feature extraction methods -> GloVe, Word2vec and w-item2vec are the most used.
Data augmentation can be a powerful tool to improve results or to alleviate the cold start problem. One technique ([paper](https://arxiv.org/abs/1606.08117)) consists in using prefixes of the original input sessions as new training sequences. Also dropout can be used.
![[data_augmentation.png]]

### Model Structure
It is evident taht we can improve performances by just incorporating attention and self-attention mechanisms in a DL-based model.
Sometimes DL-based models can be combined with traditional methods and we can register better results.
Another way to improve recommendations is to consider long-term preferences. They can be modeled by user embedded models or user recurrent models.
**User embedded models**: they can learn user representation via embedding methods, but they suffer from the [[Cold-start]] problem. Another problem is that the embeddings learnt in this way are static.
**User recurrent models**: they treat both user and item representations as recurrent components of the DL-based models. [HRNN](https://arxiv.org/abs/1706.04148) performs better than GRU4Rec by including long-term interests.

### Model training
Some strategies adopted during training can boost preformances.
**Sampling**: *popularity-based sampling* assumes that the more popular an item is, the more possiby that a user knows about it. This could tell us that, if a user does not interact with it previously, it is probable that he does not like it. *Additionl sampling* selects the negative samples with a probability proportional to $supp_i^{\alpha}$, where $supp_i$ is the support of item *i* and $\alpha$ is a parameter between 0 and 1. The cases of $\alpha=0$ and $\alpha=1$ are equivalent to uniform and popularity-based sampling respectively. Additional sampling can (sometimes) be better than uniform or popularity-based sampling.
**Mini-batch creation**:  *session parallel mini-batch training* is used to accomodate sessions of varied lengths.
**Loss function**: some types of losses frequently used are:
- TOP1 is a regularized approximation of relative rankings of positive and negative samples -> $L_{TOP1}= \dfrac{1}{N_S} \sum_{j=1}^{N_S} \sigma(r_j-r_i)+\sigma(r_j^2)$, where $\sigma$ is the sigmoid function, $r_j$ and $r_i$ are the ranking scores for samples *i* and *j* -> so the first part penalizes the incorrect ranking betweeen positive sample *i* and any negative sample *j* and the second part is used as the regularization;
- BPR is defined as follows: $L_{BPR}= -\dfrac{1}{N_S} \sum_{j=1}^{N_S} \log \sigma(r_i - r_j)$;
- TOP1-max and BPR-max can be considered as the weigthed version of TOP1 and BPR respectively -> $L_{TOP1-max}=\sum_{j=1}^{N_S}s_j(\sigma(r_j - r_i)+ \sigma(r_j^2))$ and $L_{BPR-max}-\log \sum_{J=1}^{N_S}s_j \sigma(r_i-r_j)$;
- Categorical cross-entropy (CCE) -> $CCE(o,i)=-\log(softmax(o)_i)$, where *o* is a model output and *i* is a target item. This approach suffers from the computational complexity due to the softmax;
- Hinge compares the predicted results with a pre-defined threshold: $Hinge(0,i)= \sum_{j \in C} max(0,1-o_j)+ \gamma \sum_{j \in F} max(0,o_j)$, where C is the set of recommendations containing item *i*, *F* is the set of recommendations not containing *i* and $\gamma$ is a parameter that balances the impacts of the two parts of errors. With the Hinge loss, the recommendation becomes a binary task in which the recommeder has to decide if an item should be recommended or not.

TOP1 and BPR loss function might both suffer from the gradient vanishing problems -> the max versions address this issue.

## References
1. [Sequential RS survey](https://www.ijcai.org/proceedings/2019/0883.pdf)
2. [DL for Sequential RS survey](https://arxiv.org/pdf/1905.01997.pdf)
3. [Sequential RS,PapersWithCode](https://paperswithcode.com/task/sequential-recommendation)
4. [Keras Sequential RS](https://keras.io/examples/structured_data/movielens_recommendations_transformers/)
5. [Session rs, PapersWithCode](https://paperswithcode.com/task/session-based-recommendations)
6. [Sequence-aware survey](https://arxiv.org/pdf/1802.08452.pdf)

## Code
1. [session-rec](https://github.com/rn5l/session-rec)

#### Tags
#survey #sequential_RS 